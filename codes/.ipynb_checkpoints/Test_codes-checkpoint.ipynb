{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm,iqr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spanish-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mesurement_2_pose(measurements,initial_pos=np.array([0.0,69.0,0.0,-168.0]),offset_pos=np.array([-56,-67])):\n",
    "    '''\n",
    "    Transform the raw measurement data to the global coordinate sytem\n",
    "\n",
    "    This function is specific to group 4 data\n",
    "    \n",
    "    The measurement data was stored in the format given below\n",
    "    [x_front,y_front,x_rear,y_rear]==[x2,y2,x1,y1]\n",
    "    All measurements are in mm\n",
    "    For the pose it will be convered to cm\n",
    "\n",
    "    Parameter\n",
    "    ---------------\n",
    "    measurements : The data array with manual measurements in the order [x2,y2,x1,y1]\n",
    "    initial_pos  : The starting position of front and rear marker in that order\n",
    "    offset_pos   : Offset of the origin of the marker used for measurements\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    pose         : The [x,y,theta] of the robot ->np.array\n",
    "    \n",
    "    '''\n",
    "    pose=np.zeros((measurements.shape[0],3),dtype=float)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for index,measurement in enumerate(measurements):       \n",
    "\n",
    "        ## x2,y2 are the values of front marker\n",
    "        ## Bringing the measurements to the global coordinate system by accounting for offset\n",
    "\n",
    "        x2=(measurement[0]+offset_pos[0])\n",
    "        y2=(measurement[1]+offset_pos[1])\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        ## x1,y1 are the values of rear marker\n",
    "        ## Bringing the measurements to the global coordinate system by accounting for offset\n",
    "        \n",
    "        x1=(measurement[2]+offset_pos[0])\n",
    "        y1=(measurement[3]+offset_pos[1])   \n",
    "\n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "       # Final postions wrt to global coordinates\n",
    "\n",
    "        x= ((x1-initial_pos[2])+(x2-initial_pos[0]))/2\n",
    "        y= ((y1-initial_pos[3])+(y2-initial_pos[1]))/2\n",
    "      \n",
    "       \n",
    "        \n",
    "        # np.printoptions(suppress=True)\n",
    "\n",
    "        ##Transform the angle measurement starting fromm the y axis instead of x and anticlockwise positive\n",
    "        theta=np.round(np.rad2deg(np.arctan2(y2-y1,x2-x1))-90.0,2)\n",
    "        \n",
    "       \n",
    "       #Dividing by 10 to convert to cm\n",
    "        pose[index,0]=x/10\n",
    "        pose[index,1]=y/10\n",
    "        pose[index,2]=theta\n",
    "    \n",
    "\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Import all measurement Data \n",
    "\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    group_4_data:   The [[forward],[left],[right]] motions of our group in order [x,y,orientation]\n",
    "    group_all_data: The [[forward],[left],[right]] motions of all other group in order [x,y,orientation]\n",
    "\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    ##First import our own data (Group 4)\n",
    "\n",
    "    raw_forward_measurements4=np.genfromtxt('../data/Assignment_1_2/measurements/pain_forward.csv',delimiter=',',skip_header=1)\n",
    "    raw_left_measurements4=np.genfromtxt('../data/Assignment_1_2/measurements/pain_left.csv',delimiter=',',skip_header=1)\n",
    "    raw_right_measurements4=np.genfromtxt('../data/Assignment_1_2/measurements/pain_right.csv',delimiter=',',skip_header=1)\n",
    "\n",
    "\n",
    "\n",
    "    #Transform measurements to degrees \n",
    "    forward_measurements4=transform_mesurement_2_pose(raw_forward_measurements4)\n",
    "    left_measurements4    =transform_mesurement_2_pose(raw_left_measurements4)\n",
    "    right_measurements4   = transform_mesurement_2_pose(raw_right_measurements4)\n",
    "\n",
    "\n",
    "    ##All other team data\n",
    "\n",
    "    \n",
    "    forward_measurements1=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_1_reading/front_measurement.csv',delimiter=',',skip_header=1)\n",
    "    left_measurements1=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_1_reading/left_measurement.csv',delimiter=',',skip_header=1)\n",
    "    right_measurements1=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_1_reading/right_measurement.csv',delimiter=',',skip_header=1)\n",
    "\n",
    "    ## Team 2 have bad data . Will not use it\n",
    "\n",
    "    forward_measurements2=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_2_reading/Forward.csv',delimiter=',',skip_header=1)\n",
    "    left_measurements2=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_2_reading/Left.csv',delimiter=',',skip_header=1)\n",
    "    right_measurements2=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_2_reading/Right.csv',delimiter=',',skip_header=1)\n",
    "\n",
    "\n",
    "    ##Convert Team 3 angles staring from y axis and anti-clockwise postive\n",
    "\n",
    "    forward_measurements3=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_3_reading/straight_end_poses.csv',delimiter=',',skip_header=1)\n",
    "    forward_measurements3=forward_measurements3[:,1:]\n",
    "    left_measurements3=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_3_reading/left_end_poses.csv',delimiter=',',skip_header=1)\n",
    "    left_measurements3=left_measurements3[:,1:]\n",
    "    right_measurements3=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_3_reading/right_end_poses.csv',delimiter=',',skip_header=1)\n",
    "    right_measurements3=right_measurements3[:,1:]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ##Team 5 has a different format in csv therefore have to filter it and had to convert angles to starting from y axis and anticlockwise positive\n",
    "\n",
    "    all_measurements5=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_5_reading/Manual_measurement_group5.csv',delimiter=',',skip_header=1)\n",
    "    forward_measurements5=all_measurements5[1:22,5:8]\n",
    "    left_measurements5=all_measurements5[1:22,1:4]\n",
    "    right_measurements5=all_measurements5[1:22,9:14]\n",
    "\n",
    "\n",
    "    for index in range(len(forward_measurements3)):\n",
    "        forward_measurements3[index,2]=-1*forward_measurements3[index,2]\n",
    "        left_measurements3[index,2]=-1*left_measurements3[index,2]\n",
    "        right_measurements3[index,2]=-1*right_measurements3[index,2]\n",
    "\n",
    "        forward_measurements5[index,2]=-1*forward_measurements5[index,2]\n",
    "        left_measurements5[index,2]=-1*left_measurements5[index,2]\n",
    "        right_measurements5[index,2]=-1*right_measurements5[index,2]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## Team 6 has distances in cm and angles in rads therefore have to convert it \n",
    "    \n",
    "    forward_measurements6=np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_6_reading/straight_readings.csv',delimiter=' ',skip_header=1)\n",
    "    left_measurements6=   np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_6_reading/left_readings.csv',    delimiter='',skip_header=1)\n",
    "    right_measurements6=  np.genfromtxt('../data/Assignment_1_2/Other_team_data/group_6_reading/right_readings.csv',   delimiter='',skip_header=1)\n",
    "    \n",
    "    for index in range(len(forward_measurements6)):\n",
    "        forward_measurements6[index,2]=np.rad2deg(forward_measurements6[index,2])-90.0\n",
    "        left_measurements6[index,2]=np.rad2deg(left_measurements6[index,2])-90.0\n",
    "        right_measurements6[index,2]=np.rad2deg(right_measurements6[index,2])-90.0\n",
    "\n",
    "\n",
    "    ##Combine all group data\n",
    "\n",
    "    \n",
    "    forward_measurements_all=np.concatenate((forward_measurements1,forward_measurements3,forward_measurements5,forward_measurements6),axis=0)\n",
    "\n",
    "    \n",
    "    left_measurements_all=np.concatenate((left_measurements1,left_measurements3,left_measurements5,left_measurements6),axis=0)\n",
    "    \n",
    "    \n",
    "    right_measurements_all=np.concatenate((right_measurements1,right_measurements3,right_measurements5,right_measurements6),axis=0)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    group_4_data=np.hstack((forward_measurements4,left_measurements4,right_measurements4))\n",
    "    group_all_data=np.hstack((forward_measurements_all,left_measurements_all,right_measurements_all))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return group_4_data,group_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "friendly-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, pp1, pp2):\n",
    "    '''\n",
    "        Based on \"Data Outlier Detection using the Chebyshev Theorem\",\n",
    "        Brett G. Amidan, Thomas A. Ferryman, and Scott K. Cooley\n",
    "\n",
    "        Based on the lecture slide of SEE at HBRS\n",
    "\n",
    "        Reference:\n",
    "        https://kyrcha.info/2019/11/26/data-outlier-detection-using-the-chebyshev-theorem-paper-review-and-online-adaptation\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data -- A numpy array of discrete or continuous data\n",
    "        pp1 -- likelihood of expected outliers (e.g. 0.1, 0.05 , 0.01)\n",
    "        pp2 -- final likelihood of real outliers (e.g. 0.01, 0.001 , 0.0001)\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        final_data: Data with outliers removed\n",
    "    '''\n",
    "\n",
    "    ## Create an list to store new filered data\n",
    "    filtered_data_forward=np.array([])\n",
    "    filtered_data_left=np.array([])\n",
    "    filtered_data_right=np.array([])\n",
    "\n",
    "    \n",
    "    for motion_index in [[0,3],[3,6],[6,9]]:\n",
    "        \n",
    "        current_motion=data[:,motion_index[0]:motion_index[1]]\n",
    "        ## Initialise min lenth with current motion\n",
    "        min_lenght=len(current_motion)\n",
    "        ##Loop between x and y\n",
    "        \n",
    "        for index in [0,1]:\n",
    "            current_direction=current_motion[:,index]\n",
    "            ##Mean and standard deviation of data\n",
    "            mu1 = np.mean(current_direction)\n",
    "            sigma1 = np.std(current_direction)\n",
    "\n",
    "            ## k is the no of standard deviations\n",
    "            k = 1./ np.sqrt(pp1)\n",
    "            ## Outlier detection value upper bound\n",
    "            odv1u = mu1 + k * sigma1\n",
    "            ## Outlier  detection value lower bound\n",
    "            odv1l = mu1 - k * sigma1\n",
    "            ##Filter out outliers from upper and lower bounds\n",
    "            new_data = current_direction[np.where(current_direction <= odv1u)[0]]\n",
    "            new_data = new_data[np.where(new_data >= odv1l)[0]]\n",
    "\n",
    "            ## Second stage of filternig with a tighter bound \n",
    "            mu2 = np.mean(new_data)\n",
    "            sigma2 = np.std(new_data)\n",
    "            k = 1./ np.sqrt(pp2)\n",
    "            odv2u = mu2 + k * sigma2\n",
    "            odv2l = mu2 - k * sigma2\n",
    "\n",
    "            ## Final filtered data after tighter bounds\n",
    "            final_data = new_data[np.where(new_data <= odv2u)[0]]\n",
    "            final_data = new_data[np.where(final_data >= odv2l)[0]]\n",
    "            final_data=np.transpose(final_data)\n",
    "\n",
    "            ## Check if the new filtered data is shorter than before since we want all values to have the same length\n",
    "            if min_lenght>=len(final_data):\n",
    "                min_lenght=len(final_data)\n",
    "\n",
    "            ## If data is forward motion\n",
    "\n",
    "            if motion_index[0]==0:\n",
    "\n",
    "                \n",
    "\n",
    "                ## Initialise the x values \n",
    "                if index==0:\n",
    "                   \n",
    "\n",
    "                    filtered_data_forward=final_data\n",
    "                    np.reshape(filtered_data_forward,(-1,1))\n",
    "\n",
    "                    \n",
    "                    # np.append(filtered_data_forward,final_data,axis=-1)\n",
    "\n",
    "                   \n",
    "\n",
    "\n",
    "\n",
    "                ## Adding the y values \n",
    "                else:                    \n",
    "\n",
    "                    ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                    ## make the vectors equal in length\n",
    "                    if len(filtered_data_forward)<= len(final_data):\n",
    "                        np.concatenate((filtered_data_forward,final_data[0:min_lenght]))\n",
    "\n",
    "                    ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                    ## make the vectors equal in length\n",
    "                    else:\n",
    "                        np.concatenate((filtered_data_forward[0:min_lenght],final_data))\n",
    "\n",
    "                    print(f'INsude forward y {filtered_data_forward.shape}')\n",
    "\n",
    "            ## If data is left motion\n",
    "\n",
    "            if motion_index[0]==3:\n",
    "\n",
    "                ## Initialise the x values \n",
    "                if index==0:\n",
    "                    \n",
    "                    np.append(filtered_data_left,final_data)\n",
    "\n",
    "                ## Adding the y values \n",
    "                else:                    \n",
    "\n",
    "                    ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                    ## make the vectors equal in length\n",
    "                    if len(filtered_data_left)<= min_lenght:\n",
    "                        np.hstack((filtered_data_left,final_data[0:min_lenght]))\n",
    "\n",
    "                    ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                    ## make the vectors equal in length\n",
    "                    else:\n",
    "                        filtered_data_left=np.hstack((filtered_data_left[0:min_lenght],final_data))\n",
    "            \n",
    "\n",
    "            ## If data is forward right\n",
    "\n",
    "            if motion_index[0]==6:\n",
    "\n",
    "                ## Initialise the x values \n",
    "                if index==0:\n",
    "                    \n",
    "                    np.append(filtered_data_right,final_data)\n",
    "\n",
    "                ## Adding the y values \n",
    "                else:                    \n",
    "\n",
    "                    ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                    ## make the vectors equal in length\n",
    "                    if len(filtered_data_right)<= min_lenght:\n",
    "                        np.hstack((filtered_data_right,final_data[0:min_lenght]))\n",
    "\n",
    "                    ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                    ## make the vectors equal in length\n",
    "                    else:\n",
    "                        filtered_data_right=np.hstack((filtered_data_right[0:min_lenght],final_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    min_motion_lenth=np.min([len(filtered_data_forward),len(filtered_data_left),len(filtered_data_right)])\n",
    "    print(len(filtered_data_forward),len(filtered_data_left),len(filtered_data_right))\n",
    "    filtered_data=np.hstack((filtered_data_forward[0:min_motion_lenth,:],filtered_data_left[0:min_motion_lenth,:],filtered_data_right[0:min_motion_lenth,:]))\n",
    "\n",
    "\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elegant-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_4_data,group_all_data=load_data()\n",
    "\n",
    "\n",
    "data=group_all_data\n",
    "pp1=0.1\n",
    "pp2=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "accurate-chamber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x (81,)\n",
      "inside forwards y (81,)\n",
      "81 0 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a5b9d4bb8b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0mmin_motion_lenth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0mfiltered_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_motion_lenth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiltered_data_left\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_motion_lenth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiltered_data_right\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_motion_lenth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "    Based on \"Data Outlier Detection using the Chebyshev Theorem\",\n",
    "    Brett G. Amidan, Thomas A. Ferryman, and Scott K. Cooley\n",
    "\n",
    "    Based on the lecture slide of SEE at HBRS\n",
    "\n",
    "    Reference:\n",
    "    https://kyrcha.info/2019/11/26/data-outlier-detection-using-the-chebyshev-theorem-paper-review-and-online-adaptation\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data -- A numpy array of discrete or continuous data\n",
    "    pp1 -- likelihood of expected outliers (e.g. 0.1, 0.05 , 0.01)\n",
    "    pp2 -- final likelihood of real outliers (e.g. 0.01, 0.001 , 0.0001)\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    final_data: Data with outliers removed\n",
    "'''\n",
    "\n",
    "## Create an list to store new filered data\n",
    "# filtered_data_forward=np.array([])\n",
    "filtered_data_left=np.array([])\n",
    "filtered_data_right=np.array([])\n",
    "\n",
    "\n",
    "for motion_index in [[0,3],[3,6],[6,9]]:\n",
    "    \n",
    "\n",
    "    current_motion=data[:,motion_index[0]:motion_index[1]]\n",
    "    ## Initialise min lenth with current motion\n",
    "    min_lenght=len(current_motion)\n",
    "    ##Loop between x and y\n",
    "\n",
    "    for index in [0,1]:\n",
    "        \n",
    "        current_direction=current_motion[:,index]\n",
    "        ##Mean and standard deviation of data\n",
    "        mu1 = np.mean(current_direction)\n",
    "        sigma1 = np.std(current_direction)\n",
    "\n",
    "        ## k is the no of standard deviations\n",
    "        k = 1./ np.sqrt(pp1)\n",
    "        ## Outlier detection value upper bound\n",
    "        odv1u = mu1 + k * sigma1\n",
    "        ## Outlier  detection value lower bound\n",
    "        odv1l = mu1 - k * sigma1\n",
    "        ##Filter out outliers from upper and lower bounds\n",
    "        new_data = current_direction[np.where(current_direction <= odv1u)[0]]\n",
    "        new_data = new_data[np.where(new_data >= odv1l)[0]]\n",
    "\n",
    "        ## Second stage of filternig with a tighter bound \n",
    "        mu2 = np.mean(new_data)\n",
    "        sigma2 = np.std(new_data)\n",
    "        k = 1./ np.sqrt(pp2)\n",
    "        odv2u = mu2 + k * sigma2\n",
    "        odv2l = mu2 - k * sigma2\n",
    "\n",
    "        ## Final filtered data after tighter bounds\n",
    "        final_data = new_data[np.where(new_data <= odv2u)[0]]\n",
    "        final_data = new_data[np.where(final_data >= odv2l)[0]]\n",
    "        \n",
    "\n",
    "        ## Check if the new filtered data is shorter than before since we want all values to have the same length\n",
    "        if min_lenght>=len(final_data):\n",
    "            min_lenght=len(final_data)\n",
    "\n",
    "        ## If data is forward motion\n",
    "\n",
    "        if motion_index[0]==0:\n",
    "\n",
    "\n",
    "\n",
    "            ## Initialise the x values \n",
    "            if index==0:\n",
    "\n",
    "\n",
    "                filtered_data_forward=final_data\n",
    "                filtered_data_forward[np.newaxis]\n",
    "                print(f'Shape of x {filtered_data_forward.shape}')\n",
    "#                 np.reshape(filtered_data_forward,(-1,1))\n",
    "                \n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ## Adding the y values \n",
    "            elif index==1:                    \n",
    "\n",
    "                ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                ## make the vectors equal in length\n",
    "                if len(filtered_data_forward)<= len(final_data):\n",
    "                    sss=np.vstack((filtered_data_forward,final_data[0:len(final_data)]))\n",
    "                    print(f'inside forwards y {final_data[0:len(final_data)].shape}')\n",
    "                    np.concatenate((filtered_data_forward,final_data[0:len(final_data)]))\n",
    "                    \n",
    "\n",
    "                ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                ## make the vectors equal in length\n",
    "                else:\n",
    "                    np.concatenate((filtered_data_forward[0:len(final_data)],final_data))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                \n",
    "\n",
    "        ## If data is left motion\n",
    "\n",
    "        if motion_index[0]==3:\n",
    "\n",
    "            ## Initialise the x values \n",
    "            if index==0:\n",
    "\n",
    "                np.append(filtered_data_left,final_data)\n",
    "\n",
    "            ## Adding the y values \n",
    "            else:                    \n",
    "\n",
    "                ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                ## make the vectors equal in length\n",
    "                if len(filtered_data_left)<= min_lenght:\n",
    "                    np.hstack((filtered_data_left,final_data[0:min_lenght]))\n",
    "\n",
    "                ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                ## make the vectors equal in length\n",
    "                else:\n",
    "                    filtered_data_left=np.hstack((filtered_data_left[0:min_lenght],final_data))\n",
    "\n",
    "\n",
    "        ## If data is forward right\n",
    "\n",
    "        if motion_index[0]==6:\n",
    "\n",
    "            ## Initialise the x values \n",
    "            if index==0:\n",
    "\n",
    "                np.append(filtered_data_right,final_data)\n",
    "\n",
    "            ## Adding the y values \n",
    "            else:                    \n",
    "\n",
    "                ## Check if x values are less than y values if so filter out the exrta y values to \n",
    "                ## make the vectors equal in length\n",
    "                if len(filtered_data_right)<= min_lenght:\n",
    "                    np.hstack((filtered_data_right,final_data[0:min_lenght]))\n",
    "\n",
    "                ## Check if y values are less than x values if so filter out the extra x values to \n",
    "                ## make the vectors equal in length\n",
    "                else:\n",
    "                    filtered_data_right=np.hstack((filtered_data_right[0:min_lenght],final_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "min_motion_lenth=np.min([len(filtered_data_forward),len(filtered_data_left),len(filtered_data_right)])\n",
    "print(len(filtered_data_forward),len(filtered_data_left),len(filtered_data_right))\n",
    "filtered_data=np.hstack((filtered_data_forward[0:min_motion_lenth,:],filtered_data_left[0:min_motion_lenth,:],filtered_data_right[0:min_motion_lenth,:]))\n",
    "\n",
    "\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-venue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
